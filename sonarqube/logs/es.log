2025.05.07 08:23:19 INFO  es[][o.e.n.Node] version[7.17.15], pid[26], build[default/tar/0b8ecfb4378335f4689c4223d1f1115f16bef3ba/2023-11-10T22:03:46.987399016Z], OS[Linux/5.15.167.4-microsoft-standard-WSL2/amd64], JVM[Eclipse Adoptium/OpenJDK 64-Bit Server VM/17.0.15/17.0.15+6]
2025.05.07 08:23:19 INFO  es[][o.e.n.Node] JVM home [/opt/java/openjdk]
2025.05.07 08:23:19 INFO  es[][o.e.n.Node] JVM arguments [-XX:+UseG1GC, -Djava.io.tmpdir=/opt/sonarqube/temp, -XX:ErrorFile=/opt/sonarqube/logs/es_hs_err_pid%p.log, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -Djna.tmpdir=/opt/sonarqube/temp, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=COMPAT, -Dcom.redhat.fips=false, -Xmx512m, -Xms512m, -XX:MaxDirectMemorySize=256m, -XX:+HeapDumpOnOutOfMemoryError, -Des.path.home=/opt/sonarqube/elasticsearch, -Des.path.conf=/opt/sonarqube/temp/conf/es, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=false]
2025.05.07 08:23:19 INFO  es[][o.e.p.PluginsService] loaded module [analysis-common]
2025.05.07 08:23:19 INFO  es[][o.e.p.PluginsService] loaded module [lang-painless]
2025.05.07 08:23:19 INFO  es[][o.e.p.PluginsService] loaded module [parent-join]
2025.05.07 08:23:19 INFO  es[][o.e.p.PluginsService] loaded module [reindex]
2025.05.07 08:23:19 INFO  es[][o.e.p.PluginsService] loaded module [transport-netty4]
2025.05.07 08:23:19 INFO  es[][o.e.p.PluginsService] no plugins loaded
2025.05.07 08:23:19 INFO  es[][o.e.e.NodeEnvironment] using [1] data paths, mounts [[/opt/sonarqube/data (C:\)]], net usable_space [40.8gb], net total_space [475.6gb], types [9p]
2025.05.07 08:23:19 INFO  es[][o.e.e.NodeEnvironment] heap size [512mb], compressed ordinary object pointers [true]
2025.05.07 08:23:19 INFO  es[][o.e.n.Node] node name [sonarqube], node ID [cdVIU6RDSCygofSn9PpUoQ], cluster name [sonarqube], roles [data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
2025.05.07 08:23:21 INFO  es[][o.e.t.NettyAllocator] creating NettyAllocator with the following configs: [name=unpooled, suggested_max_allocation_size=256kb, factors={es.unsafe.use_unpooled_allocator=null, g1gc_enabled=true, g1gc_region_size=1mb, heap_size=512mb}]
2025.05.07 08:23:21 INFO  es[][o.e.i.r.RecoverySettings] using rate limit [40mb] with [default=40mb, read=0b, write=0b, max=0b]
2025.05.07 08:23:21 INFO  es[][o.e.d.DiscoveryModule] using discovery type [zen] and seed hosts providers [settings]
2025.05.07 08:23:21 INFO  es[][o.e.g.DanglingIndicesState] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
2025.05.07 08:23:21 INFO  es[][o.e.n.Node] initialized
2025.05.07 08:23:21 INFO  es[][o.e.n.Node] starting ...
2025.05.07 08:23:21 INFO  es[][o.e.t.TransportService] publish_address {127.0.0.1:36749}, bound_addresses {127.0.0.1:36749}
2025.05.07 08:23:21 INFO  es[][o.e.c.c.Coordinator] setting initial configuration to VotingConfiguration{cdVIU6RDSCygofSn9PpUoQ}
2025.05.07 08:23:21 INFO  es[][o.e.c.s.MasterService] elected-as-master ([1] nodes joined)[{sonarqube}{cdVIU6RDSCygofSn9PpUoQ}{0bsvdJT9RAGTLHvJz3vSpA}{127.0.0.1}{127.0.0.1:36749}{cdfhimrsw} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 1, version: 1, delta: master node changed {previous [], current [{sonarqube}{cdVIU6RDSCygofSn9PpUoQ}{0bsvdJT9RAGTLHvJz3vSpA}{127.0.0.1}{127.0.0.1:36749}{cdfhimrsw}]}
2025.05.07 08:23:22 INFO  es[][o.e.c.c.CoordinationState] cluster UUID set to [eEkt6HxHTMC2gR0yzgff2w]
2025.05.07 08:23:22 INFO  es[][o.e.c.s.ClusterApplierService] master node changed {previous [], current [{sonarqube}{cdVIU6RDSCygofSn9PpUoQ}{0bsvdJT9RAGTLHvJz3vSpA}{127.0.0.1}{127.0.0.1:36749}{cdfhimrsw}]}, term: 1, version: 1, reason: Publication{term=1, version=1}
2025.05.07 08:23:22 INFO  es[][o.e.h.AbstractHttpServerTransport] publish_address {127.0.0.1:9001}, bound_addresses {127.0.0.1:9001}
2025.05.07 08:23:22 INFO  es[][o.e.n.Node] started
2025.05.07 08:23:22 INFO  es[][o.e.g.GatewayService] recovered [0] indices into cluster_state
2025.05.07 08:23:29 INFO  es[][o.e.c.m.MetadataCreateIndexService] [metadatas] creating index, cause [api], templates [], shards [1]/[0]
2025.05.07 08:23:30 INFO  es[][o.e.c.r.a.AllocationService] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[metadatas][0]]]).
2025.05.07 08:23:30 INFO  es[][o.e.c.m.MetadataMappingService] [metadatas/XTvYoxkDQBqBEokHjChnNA] create_mapping [metadata]
2025.05.07 08:23:30 INFO  es[][o.e.c.m.MetadataCreateIndexService] [components] creating index, cause [api], templates [], shards [5]/[0]
2025.05.07 08:23:31 INFO  es[][o.e.c.r.a.AllocationService] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[components][4]]]).
2025.05.07 08:23:31 INFO  es[][o.e.c.m.MetadataMappingService] [components/btlvT-GzSnaHDfDrzxJrXQ] create_mapping [auth]
2025.05.07 08:23:31 INFO  es[][o.e.c.m.MetadataCreateIndexService] [projectmeasures] creating index, cause [api], templates [], shards [5]/[0]
2025.05.07 08:23:32 INFO  es[][o.e.c.r.a.AllocationService] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[projectmeasures][4]]]).
2025.05.07 08:23:32 INFO  es[][o.e.c.m.MetadataMappingService] [projectmeasures/idibggnOTGivSuxoyy5MJw] create_mapping [auth]
2025.05.07 08:23:33 INFO  es[][o.e.c.m.MetadataCreateIndexService] [rules] creating index, cause [api], templates [], shards [2]/[0]
2025.05.07 08:23:33 INFO  es[][o.e.c.r.a.AllocationService] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[rules][0]]]).
2025.05.07 08:23:33 INFO  es[][o.e.c.m.MetadataMappingService] [rules/5AnfLSe-QpuuqwrMQ3AD1w] create_mapping [rule]
2025.05.07 08:23:33 INFO  es[][o.e.c.m.MetadataCreateIndexService] [issues] creating index, cause [api], templates [], shards [5]/[0]
2025.05.07 08:23:34 INFO  es[][o.e.c.r.a.AllocationService] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[issues][4]]]).
2025.05.07 08:23:34 INFO  es[][o.e.c.m.MetadataMappingService] [issues/Po_P7JOEQQeWS795jxU0Sg] create_mapping [auth]
2025.05.07 08:23:35 INFO  es[][o.e.c.m.MetadataCreateIndexService] [users] creating index, cause [api], templates [], shards [1]/[0]
2025.05.07 08:23:35 INFO  es[][o.e.c.r.a.AllocationService] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[users][0]]]).
2025.05.07 08:23:35 INFO  es[][o.e.c.m.MetadataMappingService] [users/1oSEwcdsSum8SeEaokNhRw] create_mapping [user]
2025.05.07 08:23:35 INFO  es[][o.e.c.m.MetadataCreateIndexService] [views] creating index, cause [api], templates [], shards [5]/[0]
2025.05.07 08:23:36 INFO  es[][o.e.c.r.a.AllocationService] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[views][4]]]).
2025.05.07 08:23:36 INFO  es[][o.e.c.m.MetadataMappingService] [views/ABIi-HAwT425i-_mIq7lIQ] create_mapping [view]
2025.05.07 08:23:52 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 40.6gb[8.5%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:23:55 INFO  es[][o.e.c.s.IndexScopedSettings] updating [index.refresh_interval] from [30s] to [-1]
2025.05.07 08:23:55 INFO  es[][o.e.c.s.IndexScopedSettings] updating [index.refresh_interval] from [30s] to [-1]
2025.05.07 08:23:55 INFO  es[][o.e.c.s.IndexScopedSettings] updating [index.refresh_interval] from [-1] to [30s]
2025.05.07 08:23:55 INFO  es[][o.e.c.s.IndexScopedSettings] updating [index.refresh_interval] from [-1] to [30s]
2025.05.07 08:23:55 INFO  es[][o.e.c.s.IndexScopedSettings] updating [index.refresh_interval] from [30s] to [-1]
2025.05.07 08:23:55 INFO  es[][o.e.c.s.IndexScopedSettings] updating [index.refresh_interval] from [30s] to [-1]
2025.05.07 08:23:55 INFO  es[][o.e.c.s.IndexScopedSettings] updating [index.refresh_interval] from [-1] to [30s]
2025.05.07 08:23:56 INFO  es[][o.e.c.s.IndexScopedSettings] updating [index.refresh_interval] from [-1] to [30s]
2025.05.07 08:24:52 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 40.5gb[8.5%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:26:22 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 40.4gb[8.4%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:27:22 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 40.3gb[8.4%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:28:22 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 40.3gb[8.4%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:29:22 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 40.3gb[8.4%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:30:52 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 40.2gb[8.4%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:31:52 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 40.2gb[8.4%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:32:52 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 40.1gb[8.4%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:33:52 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 40.2gb[8.4%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:35:22 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 40.2gb[8.4%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:36:22 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 40.2gb[8.4%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:37:22 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 40.2gb[8.4%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:38:22 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 39.9gb[8.4%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:39:52 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 39.9gb[8.4%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:40:52 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 39.9gb[8.3%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:41:52 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 39.9gb[8.3%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:42:52 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 39.9gb[8.3%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:44:22 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 39.9gb[8.3%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:45:22 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 40gb[8.4%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:46:22 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 40gb[8.4%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:47:22 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 40gb[8.4%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:48:22 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 40gb[8.4%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:49:52 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 40gb[8.4%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:50:52 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 40gb[8.4%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:51:52 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 40gb[8.4%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:52:52 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 40gb[8.4%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:54:22 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 39.9gb[8.4%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:55:22 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 39.9gb[8.4%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:56:22 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 40gb[8.4%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:57:22 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 38.5gb[8.1%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:58:52 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 38.4gb[8%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 08:59:52 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 38.4gb[8%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 09:00:52 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 38.4gb[8%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 09:01:52 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 38.4gb[8%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 09:03:22 WARN  es[][o.e.c.r.a.DiskThresholdMonitor] high disk watermark [90%] exceeded on [cdVIU6RDSCygofSn9PpUoQ][sonarqube][/opt/sonarqube/data/es7/nodes/0] free: 38.4gb[8%], shards will be relocated away from this node; currently relocating away shards totalling [0] bytes; the node is expected to continue to exceed the high disk watermark when these relocations are complete
2025.05.07 09:03:32 INFO  es[][o.e.n.Node] stopping ...
2025.05.07 09:03:32 INFO  es[][o.e.n.Node] stopped
2025.05.07 09:03:32 INFO  es[][o.e.n.Node] closing ...
2025.05.07 09:03:32 INFO  es[][o.e.n.Node] closed
